# Live Coding. Выбор мастера с помощью Raft Consensus Algorithm.

Известно, что эрланг предназначен для разработки распределенных
систем. Это сложная область программирования, и о ней можно много
говорить.  Но зачем говорить, когда можно просто взять, и сделать
что-нибудь интересное?

Я проведу сессию программирования на эрланг и реализую механизм выбора
мастера для кластера из эрланговских нод с помощью Raft Consensus
Algorithm.


## Обзор Raft

Raft — алгоритм для решения задач консенсуса в сети надёжных вычислений.

Есть кластер, состоящий из нескольких узлов.
Все узлы содержат копию одного и того же состояния (данные и бизнес-логика).

Для любого кластера характерно:
- часть узлов может падать (и возвращаться);
- может теряться связь между узлами;
- могут добавляться новые узлы в кластер.

При всем этом нужно как-то гарантировать, что состояния на всех узлах идентичны.
(Это и называется консенсус).

Raft предлагает способ, как этого можно добиться.

Это алгоритм общего назначения,
на основе которого можно построить разные прикладные системы.

Raft описан в работе:
"In Search of an Understandable Consensus Algorithm"
Diego Ongaro and John Ousterhout
Stanford University
http://ramcloud.stanford.edu/raft.pdf

https://raft.github.io/
Интерактивная модель
Ссылки на статьи по теме
Ссылки на реализации


## Основы Raft

При работе кластера в обычном режиме один узел выполняет роль Leader,
все остальные узлы роль Follower.

Leader принимает все запросы от клиентов, применяет их к своему состоянию,
и рассылает эти запросы всем остальным узлам, чтобы они тоже применили их
к своему состоянию.

Follower-узлы не взаимодействуют с клиентами и друг с другом, а только
получают запросы от Leader.

Leader может упасть или потерять связь с остальными узлами.
Тогда оставшиеся узлы должны выбрать нового лидера и вернуться в штатный режим работы.

Существуют промежутки времени, когда в кластере нет лидера. И в это время
кластер не может обслуживать запросы клиента (или работает только на чтение).

Период работы от одного выбора лидера до следующего выбора называется Term.
Каждый Term имеет свой номер.

img:term

Каждый запрос от клиента в терминах Raft называется Log, и каждый Log имеет свой id.
Term и log_id важны для поддержания целостности.

Алгоритм Raft делится на отдельные задачи:
- Выбор лидера
- Репликация логов
- Изменение размеров кластера


## Выбор лидера

В каждый момент времени узел может быть в одном из 3-х состояний:
Leader, Follower или Candidate.

Узел стартует в состоянии Follower и ждет запросы от лидера.
Если в течение определенного времени узел не получает запросов,
то он считает, что лидера нет, переходит в состояние Candidat,
и начинает процедуру выбора лидера.

Candidat увеличивает Term на единицу, голосует сам за себя,
и рассылает всем остальным узлам в кластере запрос Request Vote.

Follower-узлы, получив такой запрос, голосуют за кандидата.
При этом они проверяют Term, и в каждом Term голосуют только один раз,
за первого, от кого придет запрос.

Candidat какое-то время ждет ответы на свои запросы.
Тут могут случиться 3 варианта:
- кандидат получит голоса от большинства узлов в кластере, и станет лидером;
- другой узел станет лидером раньше, тогда кандидат перейдет в состояние Follower;
- никто из кандидатов не получит большинства голосов, тогда выбор лидера запускается заново.

Став лидером, узел сразу рассылает всем остальным узлам в кластере запрос Append Entries.
Этот запрос выполняет 2 роли:
- копирует лог от лидера на все остальные узлы;
- сообщает всем узлам, кто стал лидером в результате голосования.

img:states

Все запросы содержат Term. Все узлы, получив запрос Request Vote или Append Entries
сравнивают Term в запросе со своим собственным. Если Term в запросе меньше, значит
отправитель не актуален, и запрос игнорируется. Если Term в запросе больше,
значит данный узел не актуален. Он обновляет свой Term и переключается в состояние Follower.


## Репликация логов

Клиент не знает, какой из узлов в кластере является лидером. Он посылает запрос на любой узел.
Если этот узел не является лидером, он сообщает клиенту, кто лидер. И клиент еще раз посылает
свой запрос.

Запросы от клиента на каждом узле обрабатываются в два этапа.
Сперва они добавляются в очередь (append),
затем применяются к текущему состоянию узла, чтобы получить новое состояние (commit).

Лидер, получив запрос от клиента (log), присваивает ему id и добавляет его в свою очередь.
Затем он рассылает log всем остальным узлам с запросом Append Entries.
Узлы добавляют log в свою очередь, и отвечают лидеру.
Лидер собирает ответы от других узлов, и применяет лог.
Со следующим запросом Append Entries лидер сообщает, какой log id был закомичен.
И остальные узлы тоже делают commit.

Запросы Append Entries содержат Term, новые логи, и id последнего закомиченного лога.

Они также выполняют роль heart beat, сообщают остальным узлам что лидер активен.
Поэтому они периодически рассылаются даже если запросов от клиентов нет.

Возможна ситуация, когда новый лидер не успел получить все логи от старого лидера прежде, чем тот упал.
Raft имеет механизмы поддержания целостности в таких случаях, но мы их рассматривать не будем.


## Изменение размеров кластера

Raft позволяет менять конфигурацию кластера -- добавлять или удалять узлы,
без остановки кластера.

Тут есть свои нюансы, потому что информация о появлении нового узла
распространяется по кластеру не мгновенно. При выборе лидера возможна
ситуация, когда одна часть кластера не знает о появлении нового узла,
а другая часть знает.

Чтобы исключить возможность появления двух лидеров, Raft предлагает
специальный двухфазный механизм выбора лидера для такой ситуации.

Но мы этот механизм не будем разбирать.
